{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circle radius test\n",
    "Learn the function $f: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ where $f:\\bf{x} \\mapsto |x|$ with a deep neural network and compute the mutual information changes between the input, the different layer outputs and the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariosk/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.spatial as ss\n",
    "from scipy.special import digamma\n",
    "from math import log\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(fitting_history):\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(fitting_history['loss'], color='steelblue')\n",
    "    plt.plot(fitting_history['val_loss'], color='orange')\n",
    "    plt.legend(['Training loss', 'Testing loss'])\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(fitting_history['acc'], color='steelblue')\n",
    "    plt.plot(fitting_history['val_acc'], color='orange')\n",
    "    plt.legend(['Training accuracy', 'Testing accuracy'])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function and generate random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.where(np.sqrt(np.sum(x * x)) > 1.4, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_train = np.random.uniform(-1, 1, size=[100000, 6])\n",
    "Y_train = np.apply_along_axis(f, 1, X_train)\n",
    "\n",
    "X_test = np.random.uniform(-1, 1, size=[10000, 6])\n",
    "Y_test = np.apply_along_axis(f, 1, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.503300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "count  100000.000000\n",
       "mean        0.503300\n",
       "std         0.499992\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Y_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(x, k=3, base=2, seed=None):\n",
    "    assert k < len(x)\n",
    "    d, N = len(x[0]), len(x)\n",
    "    \n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    intens = 1e-10\n",
    "    small_noise_x = x + intens * np.random.rand(d)\n",
    "    \n",
    "    tree = ss.cKDTree(small_noise_x)\n",
    "    nn = tree.query(small_noise_x, k + 1, p=float('inf'), n_jobs=-1)[0][:, -1:]\n",
    "\n",
    "    const = digamma(N) - digamma(k) + d * log(2)\n",
    "    return (const + d * np.mean(np.log(nn))) / log(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_digamma(points, dvec):\n",
    "    N = len(points)\n",
    "    tree = ss.cKDTree(points)\n",
    "    avg = 0.\n",
    "    \n",
    "    for i in range(N):\n",
    "        dist = dvec[i]\n",
    "        num_points = len(tree.query_ball_point(points[i], dist - 1e-15, p=float('inf')))\n",
    "        avg += digamma(num_points) / N\n",
    "        \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(x, y, k=3, base=2, seed=None):\n",
    "    assert len(x) == len(y), \"Lists should have same length\"\n",
    "    assert k <= len(x) - 1, \"Set k smaller than num. samples - 1\"\n",
    "    \n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    intens = 1e-10\n",
    "    x_noise = x + intens * np.random.rand(len(x[0]))\n",
    "    y_noise = y + intens * np.random.rand(len(y[0]))\n",
    "    points = np.concatenate([x_noise, y_noise], axis=1)\n",
    "                   \n",
    "    tree = ss.cKDTree(points)\n",
    "    dvec = tree.query(points, k + 1, p=float('inf'), n_jobs=-1)[0][:, -1:]\n",
    "       \n",
    "    a, b, c, d = avg_digamma(x, dvec), avg_digamma(y, dvec), digamma(k), digamma(len(x))\n",
    "    return (-a - b + c + d) / log(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_entropy(x):\n",
    "    x_df = pd.DataFrame(x)\n",
    "    probabilities = (x_df\n",
    "        .reset_index()\n",
    "        .groupby(list(x_df.columns))\n",
    "        .count()) / x.shape[0]\n",
    "    \n",
    "    return - np.sum(probabilities * np.log2(probabilities))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_mutual_information(x, y, k=3, base=2, seed=None):\n",
    "    overallentropy = entropy(x, k, base, seed=seed)\n",
    "\n",
    "    n = len(y)\n",
    "    word_dict = dict()\n",
    "    for i in range(len(y)):\n",
    "        if type(y[i]) == list:\n",
    "            y[i] = tuple(y[i])\n",
    "    for sample in y:\n",
    "        word_dict[sample] = word_dict.get(sample, 0) + 1. / n\n",
    "    yvals = list(set(word_dict.keys()))\n",
    "\n",
    "    mi = overallentropy\n",
    "    for yval in yvals:\n",
    "        xgiveny = [x[i] for i in range(n) if y[i] == yval]\n",
    "        mi -= word_dict[yval] * entropy(xgiveny, k, base, seed=seed)\n",
    "    return np.abs(mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn = Sequential([\n",
    "    Dense(48, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "ffnn.compile(metrics=['accuracy'], optimizer=Adam(), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "100000/100000 [==============================] - 1s 8us/step - loss: 0.6509 - acc: 0.5433 - val_loss: 0.5312 - val_acc: 0.7433\n",
      "Epoch 2/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.4089 - acc: 0.8935 - val_loss: 0.3561 - val_acc: 0.9420\n",
      "Epoch 3/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.3307 - acc: 0.9547 - val_loss: 0.3179 - val_acc: 0.9560\n",
      "Epoch 4/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.2984 - acc: 0.9639 - val_loss: 0.2896 - val_acc: 0.9635\n",
      "Epoch 5/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.2735 - acc: 0.9682 - val_loss: 0.2706 - val_acc: 0.9632\n",
      "Epoch 6/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.2536 - acc: 0.9702 - val_loss: 0.2522 - val_acc: 0.9668\n",
      "Epoch 7/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.2364 - acc: 0.9724 - val_loss: 0.2357 - val_acc: 0.9688\n",
      "Epoch 8/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.2206 - acc: 0.9737 - val_loss: 0.2210 - val_acc: 0.9708\n",
      "Epoch 9/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.2060 - acc: 0.9750 - val_loss: 0.2060 - val_acc: 0.9711\n",
      "Epoch 10/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.1942 - acc: 0.9752 - val_loss: 0.2061 - val_acc: 0.9677\n",
      "Epoch 11/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.1831 - acc: 0.9766 - val_loss: 0.1851 - val_acc: 0.9726\n",
      "Epoch 12/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.1723 - acc: 0.9773 - val_loss: 0.1764 - val_acc: 0.9727\n",
      "Epoch 13/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.1622 - acc: 0.9777 - val_loss: 0.1681 - val_acc: 0.9724\n",
      "Epoch 14/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.1538 - acc: 0.9784 - val_loss: 0.1688 - val_acc: 0.9683\n",
      "Epoch 15/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.1463 - acc: 0.9781 - val_loss: 0.1528 - val_acc: 0.9734\n",
      "Epoch 16/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.1380 - acc: 0.9795 - val_loss: 0.1448 - val_acc: 0.9734\n",
      "Epoch 17/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.1314 - acc: 0.9795 - val_loss: 0.1404 - val_acc: 0.9735\n",
      "Epoch 18/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.1261 - acc: 0.9796 - val_loss: 0.1311 - val_acc: 0.9751\n",
      "Epoch 19/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.1188 - acc: 0.9809 - val_loss: 0.1293 - val_acc: 0.9754\n",
      "Epoch 20/500\n",
      "100000/100000 [==============================] - 1s 7us/step - loss: 0.1141 - acc: 0.9807 - val_loss: 0.1217 - val_acc: 0.9754\n",
      "Epoch 21/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.1094 - acc: 0.9810 - val_loss: 0.1186 - val_acc: 0.9771\n",
      "Epoch 22/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.1044 - acc: 0.9815 - val_loss: 0.1142 - val_acc: 0.9758\n",
      "Epoch 23/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.1007 - acc: 0.9815 - val_loss: 0.1096 - val_acc: 0.9767\n",
      "Epoch 24/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0961 - acc: 0.9816 - val_loss: 0.1044 - val_acc: 0.9779\n",
      "Epoch 25/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0930 - acc: 0.9820 - val_loss: 0.1076 - val_acc: 0.9728\n",
      "Epoch 26/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0883 - acc: 0.9826 - val_loss: 0.0974 - val_acc: 0.9772\n",
      "Epoch 27/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0849 - acc: 0.9832 - val_loss: 0.0978 - val_acc: 0.9749\n",
      "Epoch 28/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0833 - acc: 0.9824 - val_loss: 0.0957 - val_acc: 0.9766\n",
      "Epoch 29/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0803 - acc: 0.9828 - val_loss: 0.0917 - val_acc: 0.9772\n",
      "Epoch 30/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0786 - acc: 0.9824 - val_loss: 0.0919 - val_acc: 0.9764\n",
      "Epoch 31/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0741 - acc: 0.9837 - val_loss: 0.0880 - val_acc: 0.9771\n",
      "Epoch 32/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0723 - acc: 0.9840 - val_loss: 0.0876 - val_acc: 0.9766\n",
      "Epoch 33/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0720 - acc: 0.9827 - val_loss: 0.0819 - val_acc: 0.9775\n",
      "Epoch 34/500\n",
      "100000/100000 [==============================] - ETA: 0s - loss: 0.0695 - acc: 0.983 - 1s 5us/step - loss: 0.0695 - acc: 0.9832 - val_loss: 0.0859 - val_acc: 0.9748\n",
      "Epoch 35/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0685 - acc: 0.9830 - val_loss: 0.0803 - val_acc: 0.9768\n",
      "Epoch 36/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0652 - acc: 0.9835 - val_loss: 0.0800 - val_acc: 0.9763\n",
      "Epoch 37/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0630 - acc: 0.9842 - val_loss: 0.0732 - val_acc: 0.9792\n",
      "Epoch 38/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0603 - acc: 0.9849 - val_loss: 0.0772 - val_acc: 0.9780\n",
      "Epoch 39/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0596 - acc: 0.9845 - val_loss: 0.0705 - val_acc: 0.9788\n",
      "Epoch 40/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0597 - acc: 0.9843 - val_loss: 0.0742 - val_acc: 0.9769\n",
      "Epoch 41/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0579 - acc: 0.9846 - val_loss: 0.0704 - val_acc: 0.9771\n",
      "Epoch 42/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0573 - acc: 0.9842 - val_loss: 0.0679 - val_acc: 0.9787\n",
      "Epoch 43/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0546 - acc: 0.9850 - val_loss: 0.0675 - val_acc: 0.9787\n",
      "Epoch 44/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0530 - acc: 0.9851 - val_loss: 0.0679 - val_acc: 0.9796\n",
      "Epoch 45/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0515 - acc: 0.9856 - val_loss: 0.0664 - val_acc: 0.9793\n",
      "Epoch 46/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0533 - acc: 0.9843 - val_loss: 0.0677 - val_acc: 0.9771\n",
      "Epoch 47/500\n",
      "100000/100000 [==============================] - 1s 7us/step - loss: 0.0523 - acc: 0.9845 - val_loss: 0.0667 - val_acc: 0.9773\n",
      "Epoch 48/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0491 - acc: 0.9857 - val_loss: 0.0669 - val_acc: 0.9770\n",
      "Epoch 49/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0485 - acc: 0.9857 - val_loss: 0.0670 - val_acc: 0.9763\n",
      "Epoch 50/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0478 - acc: 0.9855 - val_loss: 0.0631 - val_acc: 0.9792\n",
      "Epoch 51/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0462 - acc: 0.9860 - val_loss: 0.0611 - val_acc: 0.9796\n",
      "Epoch 52/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0461 - acc: 0.9860 - val_loss: 0.0656 - val_acc: 0.9777\n",
      "Epoch 53/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0461 - acc: 0.9855 - val_loss: 0.0600 - val_acc: 0.9778\n",
      "Epoch 54/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0454 - acc: 0.9855 - val_loss: 0.0611 - val_acc: 0.9776\n",
      "Epoch 55/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0437 - acc: 0.9860 - val_loss: 0.0575 - val_acc: 0.9798\n",
      "Epoch 56/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0433 - acc: 0.9863 - val_loss: 0.0563 - val_acc: 0.9801\n",
      "Epoch 57/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0428 - acc: 0.9861 - val_loss: 0.0549 - val_acc: 0.9795\n",
      "Epoch 58/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0420 - acc: 0.9864 - val_loss: 0.0576 - val_acc: 0.9790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0426 - acc: 0.9858 - val_loss: 0.0571 - val_acc: 0.9783\n",
      "Epoch 60/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0402 - acc: 0.9866 - val_loss: 0.0530 - val_acc: 0.9808\n",
      "Epoch 61/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0418 - acc: 0.9857 - val_loss: 0.0549 - val_acc: 0.9806\n",
      "Epoch 62/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0423 - acc: 0.9857 - val_loss: 0.0543 - val_acc: 0.9797\n",
      "Epoch 63/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0384 - acc: 0.9875 - val_loss: 0.0518 - val_acc: 0.9799\n",
      "Epoch 64/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0388 - acc: 0.9867 - val_loss: 0.0533 - val_acc: 0.9798\n",
      "Epoch 65/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0388 - acc: 0.9865 - val_loss: 0.0522 - val_acc: 0.9803\n",
      "Epoch 66/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0388 - acc: 0.9864 - val_loss: 0.0566 - val_acc: 0.9786\n",
      "Epoch 67/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0374 - acc: 0.9872 - val_loss: 0.0532 - val_acc: 0.9800\n",
      "Epoch 68/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0382 - acc: 0.9863 - val_loss: 0.0503 - val_acc: 0.9803\n",
      "Epoch 69/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0367 - acc: 0.9871 - val_loss: 0.0561 - val_acc: 0.9787\n",
      "Epoch 70/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0363 - acc: 0.9869 - val_loss: 0.0533 - val_acc: 0.9792\n",
      "Epoch 71/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0380 - acc: 0.9860 - val_loss: 0.0507 - val_acc: 0.9805\n",
      "Epoch 72/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0358 - acc: 0.9871 - val_loss: 0.0507 - val_acc: 0.9796\n",
      "Epoch 73/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0376 - acc: 0.9862 - val_loss: 0.0511 - val_acc: 0.9788\n",
      "Epoch 74/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0351 - acc: 0.9870 - val_loss: 0.0487 - val_acc: 0.9799\n",
      "Epoch 75/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0350 - acc: 0.9872 - val_loss: 0.0550 - val_acc: 0.9790\n",
      "Epoch 76/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0345 - acc: 0.9876 - val_loss: 0.0519 - val_acc: 0.9792\n",
      "Epoch 77/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0333 - acc: 0.9877 - val_loss: 0.0488 - val_acc: 0.9813\n",
      "Epoch 78/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0351 - acc: 0.9871 - val_loss: 0.0637 - val_acc: 0.9766\n",
      "Epoch 79/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0342 - acc: 0.9873 - val_loss: 0.0578 - val_acc: 0.9781\n",
      "Epoch 80/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0377 - acc: 0.9856 - val_loss: 0.0502 - val_acc: 0.9789\n",
      "Epoch 81/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0329 - acc: 0.9879 - val_loss: 0.0509 - val_acc: 0.9796\n",
      "Epoch 82/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0323 - acc: 0.9875 - val_loss: 0.0504 - val_acc: 0.9794\n",
      "Epoch 83/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0330 - acc: 0.9877 - val_loss: 0.0494 - val_acc: 0.9797\n",
      "Epoch 84/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0322 - acc: 0.9878 - val_loss: 0.0507 - val_acc: 0.9799\n",
      "Epoch 85/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0320 - acc: 0.9883 - val_loss: 0.0504 - val_acc: 0.9799\n",
      "Epoch 86/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0327 - acc: 0.9876 - val_loss: 0.0559 - val_acc: 0.9788\n",
      "Epoch 87/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0335 - acc: 0.9872 - val_loss: 0.0552 - val_acc: 0.9782\n",
      "Epoch 88/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0323 - acc: 0.9875 - val_loss: 0.0516 - val_acc: 0.9786\n",
      "Epoch 89/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0321 - acc: 0.9876 - val_loss: 0.0528 - val_acc: 0.9791\n",
      "Epoch 90/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0314 - acc: 0.9880 - val_loss: 0.0489 - val_acc: 0.9809\n",
      "Epoch 91/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0318 - acc: 0.9878 - val_loss: 0.0505 - val_acc: 0.9794\n",
      "Epoch 92/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0312 - acc: 0.9880 - val_loss: 0.0495 - val_acc: 0.9807\n",
      "Epoch 93/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0306 - acc: 0.9882 - val_loss: 0.0489 - val_acc: 0.9791\n",
      "Epoch 94/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0312 - acc: 0.9880 - val_loss: 0.0477 - val_acc: 0.9807\n",
      "Epoch 95/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0307 - acc: 0.9880 - val_loss: 0.0512 - val_acc: 0.9807\n",
      "Epoch 96/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0305 - acc: 0.9884 - val_loss: 0.0501 - val_acc: 0.9801\n",
      "Epoch 97/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0303 - acc: 0.9885 - val_loss: 0.0473 - val_acc: 0.9813\n",
      "Epoch 98/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0321 - acc: 0.9875 - val_loss: 0.0555 - val_acc: 0.9784\n",
      "Epoch 99/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0316 - acc: 0.9877 - val_loss: 0.0463 - val_acc: 0.9816\n",
      "Epoch 100/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0292 - acc: 0.9886 - val_loss: 0.0473 - val_acc: 0.9811\n",
      "Epoch 101/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0293 - acc: 0.9883 - val_loss: 0.0506 - val_acc: 0.9800\n",
      "Epoch 102/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0306 - acc: 0.9879 - val_loss: 0.0457 - val_acc: 0.9813\n",
      "Epoch 103/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0310 - acc: 0.9874 - val_loss: 0.0521 - val_acc: 0.9792\n",
      "Epoch 104/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0301 - acc: 0.9882 - val_loss: 0.0478 - val_acc: 0.9803\n",
      "Epoch 105/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0317 - acc: 0.9874 - val_loss: 0.0502 - val_acc: 0.9804\n",
      "Epoch 106/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0304 - acc: 0.9879 - val_loss: 0.0447 - val_acc: 0.9812\n",
      "Epoch 107/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0289 - acc: 0.9886 - val_loss: 0.0451 - val_acc: 0.9813\n",
      "Epoch 108/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0286 - acc: 0.9890 - val_loss: 0.0486 - val_acc: 0.9803\n",
      "Epoch 109/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0282 - acc: 0.9889 - val_loss: 0.0463 - val_acc: 0.9811\n",
      "Epoch 110/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0283 - acc: 0.9889 - val_loss: 0.0463 - val_acc: 0.9807\n",
      "Epoch 111/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0302 - acc: 0.9878 - val_loss: 0.0494 - val_acc: 0.9799\n",
      "Epoch 112/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0287 - acc: 0.9887 - val_loss: 0.0476 - val_acc: 0.9810\n",
      "Epoch 113/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0284 - acc: 0.9889 - val_loss: 0.0485 - val_acc: 0.9805\n",
      "Epoch 114/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0281 - acc: 0.9891 - val_loss: 0.0448 - val_acc: 0.9818\n",
      "Epoch 115/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0294 - acc: 0.9881 - val_loss: 0.0517 - val_acc: 0.9806\n",
      "Epoch 116/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0287 - acc: 0.9883 - val_loss: 0.0498 - val_acc: 0.9798\n",
      "Epoch 117/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0286 - acc: 0.9883 - val_loss: 0.0496 - val_acc: 0.9787\n",
      "Epoch 118/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0288 - acc: 0.9884 - val_loss: 0.0498 - val_acc: 0.9794\n",
      "Epoch 119/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0272 - acc: 0.9892 - val_loss: 0.0466 - val_acc: 0.9796\n",
      "Epoch 120/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0294 - acc: 0.9883 - val_loss: 0.0472 - val_acc: 0.9790\n",
      "Epoch 121/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0270 - acc: 0.9894 - val_loss: 0.0464 - val_acc: 0.9805\n",
      "Epoch 122/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0311 - acc: 0.9871 - val_loss: 0.0575 - val_acc: 0.9780\n",
      "Epoch 123/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0307 - acc: 0.9873 - val_loss: 0.0577 - val_acc: 0.9763\n",
      "Epoch 124/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0283 - acc: 0.9887 - val_loss: 0.0435 - val_acc: 0.9827\n",
      "Epoch 125/500\n",
      "100000/100000 [==============================] - 1s 7us/step - loss: 0.0268 - acc: 0.9894 - val_loss: 0.0474 - val_acc: 0.9805\n",
      "Epoch 126/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0281 - acc: 0.9893 - val_loss: 0.0456 - val_acc: 0.9816\n",
      "Epoch 127/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.9889 - val_loss: 0.0445 - val_acc: 0.9818\n",
      "Epoch 128/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0275 - acc: 0.9888 - val_loss: 0.0582 - val_acc: 0.9768\n",
      "Epoch 129/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0269 - acc: 0.9892 - val_loss: 0.0428 - val_acc: 0.9822\n",
      "Epoch 130/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0264 - acc: 0.9896 - val_loss: 0.0465 - val_acc: 0.9806\n",
      "Epoch 131/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0267 - acc: 0.9892 - val_loss: 0.0456 - val_acc: 0.9812\n",
      "Epoch 132/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0289 - acc: 0.9880 - val_loss: 0.0491 - val_acc: 0.9816\n",
      "Epoch 133/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0266 - acc: 0.9896 - val_loss: 0.0446 - val_acc: 0.9811\n",
      "Epoch 134/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0265 - acc: 0.9891 - val_loss: 0.0453 - val_acc: 0.9810\n",
      "Epoch 135/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0264 - acc: 0.9895 - val_loss: 0.0436 - val_acc: 0.9817\n",
      "Epoch 136/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0269 - acc: 0.9891 - val_loss: 0.0454 - val_acc: 0.9818\n",
      "Epoch 137/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0270 - acc: 0.9889 - val_loss: 0.0456 - val_acc: 0.9809\n",
      "Epoch 138/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0277 - acc: 0.9885 - val_loss: 0.0464 - val_acc: 0.9806\n",
      "Epoch 139/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0278 - acc: 0.9885 - val_loss: 0.0494 - val_acc: 0.9796\n",
      "Epoch 140/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0280 - acc: 0.9885 - val_loss: 0.0455 - val_acc: 0.9812\n",
      "Epoch 141/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0267 - acc: 0.9892 - val_loss: 0.0451 - val_acc: 0.9813\n",
      "Epoch 142/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0253 - acc: 0.9900 - val_loss: 0.0445 - val_acc: 0.9818\n",
      "Epoch 143/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0268 - acc: 0.9891 - val_loss: 0.0462 - val_acc: 0.9809\n",
      "Epoch 144/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0263 - acc: 0.9895 - val_loss: 0.0431 - val_acc: 0.9821\n",
      "Epoch 145/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0270 - acc: 0.9892 - val_loss: 0.0485 - val_acc: 0.9803\n",
      "Epoch 146/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0263 - acc: 0.9892 - val_loss: 0.0480 - val_acc: 0.9812\n",
      "Epoch 147/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0266 - acc: 0.9890 - val_loss: 0.0470 - val_acc: 0.9811\n",
      "Epoch 148/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0271 - acc: 0.9889 - val_loss: 0.0554 - val_acc: 0.9784\n",
      "Epoch 149/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0272 - acc: 0.9891 - val_loss: 0.0450 - val_acc: 0.9826\n",
      "Epoch 150/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0267 - acc: 0.9889 - val_loss: 0.0508 - val_acc: 0.9801\n",
      "Epoch 151/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0261 - acc: 0.9892 - val_loss: 0.0470 - val_acc: 0.9812\n",
      "Epoch 152/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0259 - acc: 0.9896 - val_loss: 0.0523 - val_acc: 0.9793\n",
      "Epoch 153/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0271 - acc: 0.9889 - val_loss: 0.0466 - val_acc: 0.9814\n",
      "Epoch 154/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0258 - acc: 0.9897 - val_loss: 0.0461 - val_acc: 0.9803\n",
      "Epoch 155/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0257 - acc: 0.9896 - val_loss: 0.0462 - val_acc: 0.9812\n",
      "Epoch 156/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0274 - acc: 0.9889 - val_loss: 0.0441 - val_acc: 0.9813\n",
      "Epoch 157/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0264 - acc: 0.9895 - val_loss: 0.0494 - val_acc: 0.9794\n",
      "Epoch 158/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0263 - acc: 0.9889 - val_loss: 0.0446 - val_acc: 0.9813\n",
      "Epoch 159/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0258 - acc: 0.9895 - val_loss: 0.0432 - val_acc: 0.9817\n",
      "Epoch 160/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0249 - acc: 0.9900 - val_loss: 0.0455 - val_acc: 0.9828\n",
      "Epoch 161/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0248 - acc: 0.9900 - val_loss: 0.0474 - val_acc: 0.9811\n",
      "Epoch 162/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0251 - acc: 0.9899 - val_loss: 0.0429 - val_acc: 0.9822\n",
      "Epoch 163/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0454 - val_acc: 0.9809\n",
      "Epoch 164/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0275 - acc: 0.9885 - val_loss: 0.0455 - val_acc: 0.9817\n",
      "Epoch 165/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0259 - acc: 0.9893 - val_loss: 0.0433 - val_acc: 0.9823\n",
      "Epoch 166/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0260 - acc: 0.9895 - val_loss: 0.0474 - val_acc: 0.9799\n",
      "Epoch 167/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0258 - acc: 0.9896 - val_loss: 0.0448 - val_acc: 0.9817\n",
      "Epoch 168/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0257 - acc: 0.9892 - val_loss: 0.0466 - val_acc: 0.9814\n",
      "Epoch 169/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0253 - acc: 0.9896 - val_loss: 0.0452 - val_acc: 0.9817\n",
      "Epoch 170/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0256 - acc: 0.9898 - val_loss: 0.0451 - val_acc: 0.9800\n",
      "Epoch 171/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0250 - acc: 0.9898 - val_loss: 0.0484 - val_acc: 0.9808\n",
      "Epoch 172/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0250 - acc: 0.9897 - val_loss: 0.0467 - val_acc: 0.9817\n",
      "Epoch 173/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0263 - acc: 0.9894 - val_loss: 0.0444 - val_acc: 0.9822\n",
      "Epoch 174/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0256 - acc: 0.9898 - val_loss: 0.0421 - val_acc: 0.9825\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0266 - acc: 0.9890 - val_loss: 0.0429 - val_acc: 0.9838\n",
      "Epoch 176/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0257 - acc: 0.9896 - val_loss: 0.0452 - val_acc: 0.9821\n",
      "Epoch 177/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0251 - acc: 0.9899 - val_loss: 0.0426 - val_acc: 0.9818\n",
      "Epoch 178/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0242 - acc: 0.9902 - val_loss: 0.0449 - val_acc: 0.9809\n",
      "Epoch 179/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0433 - val_acc: 0.9823\n",
      "Epoch 180/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0256 - acc: 0.9899 - val_loss: 0.0457 - val_acc: 0.9807\n",
      "Epoch 181/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0234 - acc: 0.9908 - val_loss: 0.0437 - val_acc: 0.9824\n",
      "Epoch 182/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0252 - acc: 0.9899 - val_loss: 0.0479 - val_acc: 0.9811\n",
      "Epoch 183/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0254 - acc: 0.9896 - val_loss: 0.0507 - val_acc: 0.9795\n",
      "Epoch 184/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0259 - acc: 0.9894 - val_loss: 0.0473 - val_acc: 0.9803\n",
      "Epoch 185/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0241 - acc: 0.9903 - val_loss: 0.0463 - val_acc: 0.9817\n",
      "Epoch 186/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0252 - acc: 0.9895 - val_loss: 0.0447 - val_acc: 0.9820\n",
      "Epoch 187/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0239 - acc: 0.9901 - val_loss: 0.0427 - val_acc: 0.9827\n",
      "Epoch 188/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0249 - acc: 0.9898 - val_loss: 0.0442 - val_acc: 0.9829\n",
      "Epoch 189/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0262 - acc: 0.9892 - val_loss: 0.0428 - val_acc: 0.9829\n",
      "Epoch 190/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0234 - acc: 0.9901 - val_loss: 0.0438 - val_acc: 0.9821\n",
      "Epoch 191/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0243 - acc: 0.9901 - val_loss: 0.0452 - val_acc: 0.9812\n",
      "Epoch 192/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0242 - acc: 0.9903 - val_loss: 0.0449 - val_acc: 0.9810\n",
      "Epoch 193/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0240 - acc: 0.9900 - val_loss: 0.0471 - val_acc: 0.9806\n",
      "Epoch 194/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0252 - acc: 0.9896 - val_loss: 0.0472 - val_acc: 0.9811\n",
      "Epoch 195/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0245 - acc: 0.9899 - val_loss: 0.0447 - val_acc: 0.9803\n",
      "Epoch 196/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0248 - acc: 0.9897 - val_loss: 0.0441 - val_acc: 0.9831\n",
      "Epoch 197/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0255 - acc: 0.9893 - val_loss: 0.0502 - val_acc: 0.9807\n",
      "Epoch 198/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0239 - acc: 0.9902 - val_loss: 0.0511 - val_acc: 0.9811\n",
      "Epoch 199/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0247 - acc: 0.9899 - val_loss: 0.0478 - val_acc: 0.9805\n",
      "Epoch 200/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0229 - acc: 0.9910 - val_loss: 0.0432 - val_acc: 0.9823\n",
      "Epoch 201/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0258 - acc: 0.9893 - val_loss: 0.0461 - val_acc: 0.9817\n",
      "Epoch 202/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0256 - acc: 0.9894 - val_loss: 0.0464 - val_acc: 0.9811\n",
      "Epoch 203/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0243 - acc: 0.9902 - val_loss: 0.0471 - val_acc: 0.9811\n",
      "Epoch 204/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0235 - acc: 0.9905 - val_loss: 0.0405 - val_acc: 0.9827\n",
      "Epoch 205/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0234 - acc: 0.9902 - val_loss: 0.0452 - val_acc: 0.9813\n",
      "Epoch 206/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0232 - acc: 0.9906 - val_loss: 0.0503 - val_acc: 0.9806\n",
      "Epoch 207/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0249 - acc: 0.9900 - val_loss: 0.0421 - val_acc: 0.9824\n",
      "Epoch 208/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0273 - acc: 0.9884 - val_loss: 0.0425 - val_acc: 0.9830\n",
      "Epoch 209/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0242 - acc: 0.9899 - val_loss: 0.0412 - val_acc: 0.9836\n",
      "Epoch 210/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0244 - acc: 0.9898 - val_loss: 0.0481 - val_acc: 0.9812\n",
      "Epoch 211/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0237 - acc: 0.9901 - val_loss: 0.0417 - val_acc: 0.9825\n",
      "Epoch 212/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0234 - acc: 0.9905 - val_loss: 0.0431 - val_acc: 0.9814\n",
      "Epoch 213/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0239 - acc: 0.9899 - val_loss: 0.0449 - val_acc: 0.9819\n",
      "Epoch 214/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0443 - val_acc: 0.9817\n",
      "Epoch 215/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0229 - acc: 0.9903 - val_loss: 0.0440 - val_acc: 0.9821\n",
      "Epoch 216/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0242 - acc: 0.9899 - val_loss: 0.0447 - val_acc: 0.9820\n",
      "Epoch 217/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0472 - val_acc: 0.9810\n",
      "Epoch 218/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0234 - acc: 0.9904 - val_loss: 0.0409 - val_acc: 0.9833\n",
      "Epoch 219/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0238 - acc: 0.9899 - val_loss: 0.0483 - val_acc: 0.9830\n",
      "Epoch 220/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0260 - acc: 0.9893 - val_loss: 0.0464 - val_acc: 0.9818\n",
      "Epoch 221/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0234 - acc: 0.9903 - val_loss: 0.0445 - val_acc: 0.9820\n",
      "Epoch 222/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0248 - acc: 0.9897 - val_loss: 0.0435 - val_acc: 0.9821\n",
      "Epoch 223/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0236 - acc: 0.9901 - val_loss: 0.0442 - val_acc: 0.9810\n",
      "Epoch 224/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0230 - acc: 0.9907 - val_loss: 0.0441 - val_acc: 0.9817\n",
      "Epoch 225/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0238 - acc: 0.9900 - val_loss: 0.0429 - val_acc: 0.9825\n",
      "Epoch 226/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0224 - acc: 0.9904 - val_loss: 0.0482 - val_acc: 0.9820\n",
      "Epoch 227/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0246 - acc: 0.9897 - val_loss: 0.0486 - val_acc: 0.9811\n",
      "Epoch 228/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0258 - acc: 0.9893 - val_loss: 0.0441 - val_acc: 0.9820\n",
      "Epoch 229/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9907 - val_loss: 0.0454 - val_acc: 0.9817\n",
      "Epoch 230/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0234 - acc: 0.9905 - val_loss: 0.0414 - val_acc: 0.9832\n",
      "Epoch 231/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0234 - acc: 0.9904 - val_loss: 0.0448 - val_acc: 0.9830\n",
      "Epoch 232/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0243 - acc: 0.9900 - val_loss: 0.0456 - val_acc: 0.9820\n",
      "Epoch 233/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0235 - acc: 0.9904 - val_loss: 0.0533 - val_acc: 0.9800\n",
      "Epoch 234/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0234 - acc: 0.9904 - val_loss: 0.0422 - val_acc: 0.9831\n",
      "Epoch 235/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0233 - acc: 0.9903 - val_loss: 0.0510 - val_acc: 0.9801\n",
      "Epoch 236/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0239 - acc: 0.9903 - val_loss: 0.0469 - val_acc: 0.9814\n",
      "Epoch 237/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0233 - acc: 0.9904 - val_loss: 0.0469 - val_acc: 0.9806\n",
      "Epoch 238/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0230 - acc: 0.9906 - val_loss: 0.0415 - val_acc: 0.9821\n",
      "Epoch 239/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0223 - acc: 0.9909 - val_loss: 0.0432 - val_acc: 0.9832\n",
      "Epoch 240/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0222 - acc: 0.9910 - val_loss: 0.0479 - val_acc: 0.9801\n",
      "Epoch 241/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0231 - acc: 0.9906 - val_loss: 0.0509 - val_acc: 0.9800\n",
      "Epoch 242/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0233 - acc: 0.9904 - val_loss: 0.0461 - val_acc: 0.9819\n",
      "Epoch 243/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9909 - val_loss: 0.0468 - val_acc: 0.9815\n",
      "Epoch 244/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0228 - acc: 0.9907 - val_loss: 0.0448 - val_acc: 0.9834\n",
      "Epoch 245/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0229 - acc: 0.9905 - val_loss: 0.0512 - val_acc: 0.9812\n",
      "Epoch 246/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0233 - acc: 0.9903 - val_loss: 0.0409 - val_acc: 0.9835\n",
      "Epoch 247/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0247 - acc: 0.9896 - val_loss: 0.0438 - val_acc: 0.9826\n",
      "Epoch 248/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0227 - acc: 0.9909 - val_loss: 0.0418 - val_acc: 0.9833\n",
      "Epoch 249/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9906 - val_loss: 0.0429 - val_acc: 0.9828\n",
      "Epoch 250/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0242 - acc: 0.9902 - val_loss: 0.0459 - val_acc: 0.9823\n",
      "Epoch 251/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0232 - acc: 0.9904 - val_loss: 0.0446 - val_acc: 0.9832\n",
      "Epoch 252/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0214 - acc: 0.9912 - val_loss: 0.0405 - val_acc: 0.9837\n",
      "Epoch 253/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0226 - acc: 0.9908 - val_loss: 0.0444 - val_acc: 0.9827\n",
      "Epoch 254/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0222 - acc: 0.9909 - val_loss: 0.0445 - val_acc: 0.9818\n",
      "Epoch 255/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0227 - acc: 0.9909 - val_loss: 0.0428 - val_acc: 0.9841\n",
      "Epoch 256/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0226 - acc: 0.9905 - val_loss: 0.0424 - val_acc: 0.9830\n",
      "Epoch 257/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0236 - acc: 0.9902 - val_loss: 0.0519 - val_acc: 0.9804\n",
      "Epoch 258/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0221 - acc: 0.9910 - val_loss: 0.0482 - val_acc: 0.9805\n",
      "Epoch 259/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0222 - acc: 0.9909 - val_loss: 0.0450 - val_acc: 0.9834\n",
      "Epoch 260/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9906 - val_loss: 0.0415 - val_acc: 0.9834\n",
      "Epoch 261/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0231 - acc: 0.9905 - val_loss: 0.0457 - val_acc: 0.9824\n",
      "Epoch 262/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0220 - acc: 0.9910 - val_loss: 0.0490 - val_acc: 0.9813\n",
      "Epoch 263/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0249 - acc: 0.9896 - val_loss: 0.0429 - val_acc: 0.9835\n",
      "Epoch 264/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0231 - acc: 0.9905 - val_loss: 0.0429 - val_acc: 0.9822\n",
      "Epoch 265/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0218 - acc: 0.9911 - val_loss: 0.0441 - val_acc: 0.9822\n",
      "Epoch 266/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0209 - acc: 0.9915 - val_loss: 0.0490 - val_acc: 0.9815\n",
      "Epoch 267/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0221 - acc: 0.9907 - val_loss: 0.0421 - val_acc: 0.9826\n",
      "Epoch 268/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9907 - val_loss: 0.0447 - val_acc: 0.9817\n",
      "Epoch 269/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0220 - acc: 0.9912 - val_loss: 0.0412 - val_acc: 0.9837\n",
      "Epoch 270/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0226 - acc: 0.9908 - val_loss: 0.0487 - val_acc: 0.9804\n",
      "Epoch 271/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0239 - acc: 0.9900 - val_loss: 0.0462 - val_acc: 0.9830\n",
      "Epoch 272/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0216 - acc: 0.9914 - val_loss: 0.0463 - val_acc: 0.9823\n",
      "Epoch 273/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0222 - acc: 0.9907 - val_loss: 0.0409 - val_acc: 0.9842\n",
      "Epoch 274/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0231 - acc: 0.9906 - val_loss: 0.0434 - val_acc: 0.9825\n",
      "Epoch 275/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0222 - acc: 0.9908 - val_loss: 0.0439 - val_acc: 0.9822\n",
      "Epoch 276/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0239 - acc: 0.9900 - val_loss: 0.0432 - val_acc: 0.9830\n",
      "Epoch 277/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0226 - acc: 0.9907 - val_loss: 0.0427 - val_acc: 0.9827\n",
      "Epoch 278/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9906 - val_loss: 0.0447 - val_acc: 0.9827\n",
      "Epoch 279/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0227 - acc: 0.9905 - val_loss: 0.0459 - val_acc: 0.9820\n",
      "Epoch 280/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0223 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9834\n",
      "Epoch 281/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0242 - acc: 0.9901 - val_loss: 0.0500 - val_acc: 0.9807\n",
      "Epoch 282/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9906 - val_loss: 0.0407 - val_acc: 0.9839\n",
      "Epoch 283/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0210 - acc: 0.9914 - val_loss: 0.0424 - val_acc: 0.9833\n",
      "Epoch 284/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0220 - acc: 0.9909 - val_loss: 0.0456 - val_acc: 0.9821\n",
      "Epoch 285/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0219 - acc: 0.9911 - val_loss: 0.0479 - val_acc: 0.9815\n",
      "Epoch 286/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0212 - acc: 0.9913 - val_loss: 0.0428 - val_acc: 0.9827\n",
      "Epoch 287/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0210 - acc: 0.9914 - val_loss: 0.0442 - val_acc: 0.9835\n",
      "Epoch 288/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0218 - acc: 0.9912 - val_loss: 0.0423 - val_acc: 0.9827\n",
      "Epoch 289/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0212 - acc: 0.9914 - val_loss: 0.0470 - val_acc: 0.9810\n",
      "Epoch 290/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0215 - acc: 0.9911 - val_loss: 0.0436 - val_acc: 0.9832\n",
      "Epoch 291/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0214 - acc: 0.9914 - val_loss: 0.0431 - val_acc: 0.9831\n",
      "Epoch 292/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0232 - acc: 0.9900 - val_loss: 0.0436 - val_acc: 0.9836\n",
      "Epoch 293/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0232 - acc: 0.9908 - val_loss: 0.0545 - val_acc: 0.9774\n",
      "Epoch 294/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0219 - acc: 0.9911 - val_loss: 0.0422 - val_acc: 0.9826\n",
      "Epoch 295/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0224 - acc: 0.9907 - val_loss: 0.0552 - val_acc: 0.9799\n",
      "Epoch 296/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0242 - acc: 0.9901 - val_loss: 0.0486 - val_acc: 0.9814\n",
      "Epoch 297/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0216 - acc: 0.9912 - val_loss: 0.0409 - val_acc: 0.9838\n",
      "Epoch 298/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0219 - acc: 0.9908 - val_loss: 0.0418 - val_acc: 0.9826\n",
      "Epoch 299/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0204 - acc: 0.9916 - val_loss: 0.0434 - val_acc: 0.9824\n",
      "Epoch 300/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0231 - acc: 0.9904 - val_loss: 0.0484 - val_acc: 0.9836\n",
      "Epoch 301/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0209 - acc: 0.9915 - val_loss: 0.0491 - val_acc: 0.9823\n",
      "Epoch 302/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0208 - acc: 0.9916 - val_loss: 0.0444 - val_acc: 0.9820\n",
      "Epoch 303/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0244 - acc: 0.9898 - val_loss: 0.0429 - val_acc: 0.9832\n",
      "Epoch 304/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0213 - acc: 0.9914 - val_loss: 0.0410 - val_acc: 0.9838\n",
      "Epoch 305/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0218 - acc: 0.9913 - val_loss: 0.0528 - val_acc: 0.9808\n",
      "Epoch 306/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0210 - acc: 0.9912 - val_loss: 0.0432 - val_acc: 0.9826\n",
      "Epoch 307/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0207 - acc: 0.9918 - val_loss: 0.0412 - val_acc: 0.9829\n",
      "Epoch 308/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0226 - acc: 0.9906 - val_loss: 0.0440 - val_acc: 0.9836\n",
      "Epoch 309/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0206 - acc: 0.9915 - val_loss: 0.0427 - val_acc: 0.9838\n",
      "Epoch 310/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0237 - acc: 0.9901 - val_loss: 0.0491 - val_acc: 0.9818\n",
      "Epoch 311/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0220 - acc: 0.9909 - val_loss: 0.0403 - val_acc: 0.9847\n",
      "Epoch 312/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0229 - acc: 0.9902 - val_loss: 0.0491 - val_acc: 0.9826\n",
      "Epoch 313/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0220 - acc: 0.9908 - val_loss: 0.0460 - val_acc: 0.9814\n",
      "Epoch 314/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0208 - acc: 0.9913 - val_loss: 0.0420 - val_acc: 0.9833\n",
      "Epoch 315/500\n",
      "100000/100000 [==============================] - 1s 7us/step - loss: 0.0202 - acc: 0.9919 - val_loss: 0.0471 - val_acc: 0.9810\n",
      "Epoch 316/500\n",
      "100000/100000 [==============================] - 1s 7us/step - loss: 0.0212 - acc: 0.9913 - val_loss: 0.0420 - val_acc: 0.9837\n",
      "Epoch 317/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0212 - acc: 0.9916 - val_loss: 0.0457 - val_acc: 0.9824\n",
      "Epoch 318/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0223 - acc: 0.9909 - val_loss: 0.0406 - val_acc: 0.9836\n",
      "Epoch 319/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0213 - acc: 0.9911 - val_loss: 0.0461 - val_acc: 0.9825\n",
      "Epoch 320/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0241 - acc: 0.9903 - val_loss: 0.0466 - val_acc: 0.9837\n",
      "Epoch 321/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0210 - acc: 0.9913 - val_loss: 0.0435 - val_acc: 0.9838\n",
      "Epoch 322/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0208 - acc: 0.9914 - val_loss: 0.0452 - val_acc: 0.9825\n",
      "Epoch 323/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0209 - acc: 0.9916 - val_loss: 0.0419 - val_acc: 0.9836\n",
      "Epoch 324/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0203 - acc: 0.9918 - val_loss: 0.0454 - val_acc: 0.9837\n",
      "Epoch 325/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0208 - acc: 0.9915 - val_loss: 0.0450 - val_acc: 0.9834\n",
      "Epoch 326/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0218 - acc: 0.9909 - val_loss: 0.0422 - val_acc: 0.9829\n",
      "Epoch 327/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0212 - acc: 0.9914 - val_loss: 0.0467 - val_acc: 0.9810\n",
      "Epoch 328/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0212 - acc: 0.9913 - val_loss: 0.0422 - val_acc: 0.9836\n",
      "Epoch 329/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0206 - acc: 0.9916 - val_loss: 0.0538 - val_acc: 0.9808\n",
      "Epoch 330/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0212 - acc: 0.9914 - val_loss: 0.0428 - val_acc: 0.9833\n",
      "Epoch 331/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0205 - acc: 0.9915 - val_loss: 0.0464 - val_acc: 0.9834\n",
      "Epoch 332/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0226 - acc: 0.9907 - val_loss: 0.0530 - val_acc: 0.9811\n",
      "Epoch 333/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0216 - acc: 0.9910 - val_loss: 0.0425 - val_acc: 0.9835\n",
      "Epoch 334/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0206 - acc: 0.9916 - val_loss: 0.0419 - val_acc: 0.9827\n",
      "Epoch 335/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0200 - acc: 0.9918 - val_loss: 0.0427 - val_acc: 0.9828\n",
      "Epoch 336/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0194 - acc: 0.9922 - val_loss: 0.0440 - val_acc: 0.9818\n",
      "Epoch 337/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0206 - acc: 0.9916 - val_loss: 0.0451 - val_acc: 0.9822\n",
      "Epoch 338/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0201 - acc: 0.9919 - val_loss: 0.0435 - val_acc: 0.9831\n",
      "Epoch 339/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0202 - acc: 0.9918 - val_loss: 0.0493 - val_acc: 0.9814\n",
      "Epoch 340/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0207 - acc: 0.9916 - val_loss: 0.0444 - val_acc: 0.9816\n",
      "Epoch 341/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0223 - acc: 0.9910 - val_loss: 0.0476 - val_acc: 0.9817\n",
      "Epoch 342/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0247 - acc: 0.9897 - val_loss: 0.0431 - val_acc: 0.9826\n",
      "Epoch 343/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0215 - acc: 0.9910 - val_loss: 0.0434 - val_acc: 0.9830\n",
      "Epoch 344/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0223 - acc: 0.9906 - val_loss: 0.0417 - val_acc: 0.9829\n",
      "Epoch 345/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0202 - acc: 0.9917 - val_loss: 0.0440 - val_acc: 0.9841\n",
      "Epoch 346/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0197 - acc: 0.9919 - val_loss: 0.0407 - val_acc: 0.9839\n",
      "Epoch 347/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0203 - acc: 0.9915 - val_loss: 0.0436 - val_acc: 0.9821\n",
      "Epoch 348/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0209 - acc: 0.9914 - val_loss: 0.0438 - val_acc: 0.9823\n",
      "Epoch 349/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0219 - acc: 0.9909 - val_loss: 0.0447 - val_acc: 0.9831\n",
      "Epoch 350/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0199 - acc: 0.9920 - val_loss: 0.0524 - val_acc: 0.9797\n",
      "Epoch 351/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0222 - acc: 0.9908 - val_loss: 0.0429 - val_acc: 0.9830\n",
      "Epoch 352/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0205 - acc: 0.9913 - val_loss: 0.0601 - val_acc: 0.9786\n",
      "Epoch 353/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0227 - acc: 0.9906 - val_loss: 0.0443 - val_acc: 0.9821\n",
      "Epoch 354/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0205 - acc: 0.9914 - val_loss: 0.0431 - val_acc: 0.9830\n",
      "Epoch 355/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0204 - acc: 0.9916 - val_loss: 0.0438 - val_acc: 0.9835\n",
      "Epoch 356/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0196 - acc: 0.9922 - val_loss: 0.0480 - val_acc: 0.9817\n",
      "Epoch 357/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0205 - acc: 0.9914 - val_loss: 0.0502 - val_acc: 0.9808\n",
      "Epoch 358/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0210 - acc: 0.9913 - val_loss: 0.0469 - val_acc: 0.9822\n",
      "Epoch 359/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0207 - acc: 0.9915 - val_loss: 0.0409 - val_acc: 0.9833\n",
      "Epoch 360/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0204 - acc: 0.9918 - val_loss: 0.0458 - val_acc: 0.9825\n",
      "Epoch 361/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0215 - acc: 0.9910 - val_loss: 0.0446 - val_acc: 0.9834\n",
      "Epoch 362/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0203 - acc: 0.9916 - val_loss: 0.0469 - val_acc: 0.9818\n",
      "Epoch 363/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0211 - acc: 0.9912 - val_loss: 0.0447 - val_acc: 0.9816\n",
      "Epoch 364/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0198 - acc: 0.9915 - val_loss: 0.0417 - val_acc: 0.9836\n",
      "Epoch 365/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0196 - acc: 0.9923 - val_loss: 0.0547 - val_acc: 0.9799\n",
      "Epoch 366/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0219 - acc: 0.9906 - val_loss: 0.0447 - val_acc: 0.9826\n",
      "Epoch 367/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0185 - acc: 0.9925 - val_loss: 0.0450 - val_acc: 0.9826\n",
      "Epoch 368/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0214 - acc: 0.9910 - val_loss: 0.0437 - val_acc: 0.9834\n",
      "Epoch 369/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0225 - acc: 0.9908 - val_loss: 0.0442 - val_acc: 0.9825\n",
      "Epoch 370/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0197 - acc: 0.9919 - val_loss: 0.0457 - val_acc: 0.9826\n",
      "Epoch 371/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0198 - acc: 0.9917 - val_loss: 0.0454 - val_acc: 0.9813\n",
      "Epoch 372/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0191 - acc: 0.9922 - val_loss: 0.0444 - val_acc: 0.9835\n",
      "Epoch 373/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0188 - acc: 0.9921 - val_loss: 0.0443 - val_acc: 0.9835\n",
      "Epoch 374/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0190 - acc: 0.9923 - val_loss: 0.0416 - val_acc: 0.9840\n",
      "Epoch 375/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0191 - acc: 0.9922 - val_loss: 0.0428 - val_acc: 0.9838\n",
      "Epoch 376/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0218 - acc: 0.9910 - val_loss: 0.0462 - val_acc: 0.9821\n",
      "Epoch 377/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0197 - acc: 0.9920 - val_loss: 0.0431 - val_acc: 0.9833\n",
      "Epoch 378/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0193 - acc: 0.9920 - val_loss: 0.0434 - val_acc: 0.9833\n",
      "Epoch 379/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0222 - acc: 0.9907 - val_loss: 0.0547 - val_acc: 0.9803\n",
      "Epoch 380/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0207 - acc: 0.9916 - val_loss: 0.0442 - val_acc: 0.9836\n",
      "Epoch 381/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0196 - acc: 0.9920 - val_loss: 0.0444 - val_acc: 0.9831\n",
      "Epoch 382/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0195 - acc: 0.9919 - val_loss: 0.0482 - val_acc: 0.9826\n",
      "Epoch 383/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0215 - acc: 0.9912 - val_loss: 0.0416 - val_acc: 0.9845\n",
      "Epoch 384/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0207 - acc: 0.9914 - val_loss: 0.0497 - val_acc: 0.9824\n",
      "Epoch 385/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0210 - acc: 0.9913 - val_loss: 0.0459 - val_acc: 0.9814\n",
      "Epoch 386/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0201 - acc: 0.9915 - val_loss: 0.0459 - val_acc: 0.9807\n",
      "Epoch 387/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0215 - acc: 0.9910 - val_loss: 0.0501 - val_acc: 0.9830\n",
      "Epoch 388/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0212 - acc: 0.9916 - val_loss: 0.0440 - val_acc: 0.9821\n",
      "Epoch 389/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0201 - acc: 0.9918 - val_loss: 0.0447 - val_acc: 0.9822\n",
      "Epoch 390/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0205 - acc: 0.9915 - val_loss: 0.0442 - val_acc: 0.9829\n",
      "Epoch 391/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0222 - acc: 0.9906 - val_loss: 0.0548 - val_acc: 0.9793\n",
      "Epoch 392/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0212 - acc: 0.9909 - val_loss: 0.0413 - val_acc: 0.9834\n",
      "Epoch 393/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0216 - acc: 0.9911 - val_loss: 0.0463 - val_acc: 0.9815\n",
      "Epoch 394/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0205 - acc: 0.9914 - val_loss: 0.0434 - val_acc: 0.9833\n",
      "Epoch 395/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0193 - acc: 0.9921 - val_loss: 0.0438 - val_acc: 0.9838\n",
      "Epoch 396/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0199 - acc: 0.9918 - val_loss: 0.0533 - val_acc: 0.9808\n",
      "Epoch 397/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0211 - acc: 0.9913 - val_loss: 0.0429 - val_acc: 0.9845\n",
      "Epoch 398/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9905 - val_loss: 0.0440 - val_acc: 0.9841\n",
      "Epoch 399/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0215 - acc: 0.9910 - val_loss: 0.0452 - val_acc: 0.9813\n",
      "Epoch 400/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0203 - acc: 0.9916 - val_loss: 0.0482 - val_acc: 0.9806\n",
      "Epoch 401/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0198 - acc: 0.9918 - val_loss: 0.0509 - val_acc: 0.9805\n",
      "Epoch 402/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0200 - acc: 0.9917 - val_loss: 0.0452 - val_acc: 0.9833\n",
      "Epoch 403/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0207 - acc: 0.9913 - val_loss: 0.0472 - val_acc: 0.9823\n",
      "Epoch 404/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0186 - acc: 0.9926 - val_loss: 0.0439 - val_acc: 0.9822\n",
      "Epoch 405/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0189 - acc: 0.9922 - val_loss: 0.0515 - val_acc: 0.9810\n",
      "Epoch 406/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0200 - acc: 0.9916 - val_loss: 0.0478 - val_acc: 0.9820\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0196 - acc: 0.9920 - val_loss: 0.0426 - val_acc: 0.9839\n",
      "Epoch 408/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0210 - acc: 0.9912 - val_loss: 0.0497 - val_acc: 0.9815\n",
      "Epoch 409/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0190 - acc: 0.9922 - val_loss: 0.0449 - val_acc: 0.9831\n",
      "Epoch 410/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0207 - acc: 0.9914 - val_loss: 0.0462 - val_acc: 0.9812\n",
      "Epoch 411/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0190 - acc: 0.9923 - val_loss: 0.0445 - val_acc: 0.9829\n",
      "Epoch 412/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0196 - acc: 0.9918 - val_loss: 0.0460 - val_acc: 0.9819\n",
      "Epoch 413/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0196 - acc: 0.9919 - val_loss: 0.0473 - val_acc: 0.9830\n",
      "Epoch 414/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0211 - acc: 0.9912 - val_loss: 0.0470 - val_acc: 0.9831\n",
      "Epoch 415/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0193 - acc: 0.9921 - val_loss: 0.0456 - val_acc: 0.9828\n",
      "Epoch 416/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0203 - acc: 0.9917 - val_loss: 0.0445 - val_acc: 0.9827\n",
      "Epoch 417/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0202 - acc: 0.9917 - val_loss: 0.0468 - val_acc: 0.9818\n",
      "Epoch 418/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0213 - acc: 0.9912 - val_loss: 0.0418 - val_acc: 0.9825\n",
      "Epoch 419/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0203 - acc: 0.9915 - val_loss: 0.0459 - val_acc: 0.9828\n",
      "Epoch 420/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0192 - acc: 0.9920 - val_loss: 0.0464 - val_acc: 0.9826\n",
      "Epoch 421/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0200 - acc: 0.9917 - val_loss: 0.0589 - val_acc: 0.9796\n",
      "Epoch 422/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0201 - acc: 0.9917 - val_loss: 0.0449 - val_acc: 0.9830\n",
      "Epoch 423/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0191 - acc: 0.9922 - val_loss: 0.0455 - val_acc: 0.9825\n",
      "Epoch 424/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0191 - acc: 0.9922 - val_loss: 0.0462 - val_acc: 0.9817\n",
      "Epoch 425/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0202 - acc: 0.9914 - val_loss: 0.0452 - val_acc: 0.9824\n",
      "Epoch 426/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0208 - acc: 0.9914 - val_loss: 0.0432 - val_acc: 0.9825\n",
      "Epoch 427/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0200 - acc: 0.9917 - val_loss: 0.0534 - val_acc: 0.9803\n",
      "Epoch 428/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0205 - acc: 0.9914 - val_loss: 0.0443 - val_acc: 0.9819\n",
      "Epoch 429/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0185 - acc: 0.9923 - val_loss: 0.0427 - val_acc: 0.9827\n",
      "Epoch 430/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0184 - acc: 0.9924 - val_loss: 0.0424 - val_acc: 0.9825\n",
      "Epoch 431/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0212 - acc: 0.9912 - val_loss: 0.0451 - val_acc: 0.9823\n",
      "Epoch 432/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0191 - acc: 0.9920 - val_loss: 0.0419 - val_acc: 0.9842\n",
      "Epoch 433/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0187 - acc: 0.9922 - val_loss: 0.0450 - val_acc: 0.9825\n",
      "Epoch 434/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0209 - acc: 0.9913 - val_loss: 0.0478 - val_acc: 0.9809\n",
      "Epoch 435/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0189 - acc: 0.9922 - val_loss: 0.0453 - val_acc: 0.9821\n",
      "Epoch 436/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0205 - acc: 0.9915 - val_loss: 0.0450 - val_acc: 0.9822\n",
      "Epoch 437/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0188 - acc: 0.9925 - val_loss: 0.0439 - val_acc: 0.9824\n",
      "Epoch 438/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0181 - acc: 0.9926 - val_loss: 0.0442 - val_acc: 0.9836\n",
      "Epoch 439/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0197 - acc: 0.9918 - val_loss: 0.0453 - val_acc: 0.9838\n",
      "Epoch 440/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0209 - acc: 0.9914 - val_loss: 0.0422 - val_acc: 0.9827\n",
      "Epoch 441/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0192 - acc: 0.9919 - val_loss: 0.0475 - val_acc: 0.9810\n",
      "Epoch 442/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0189 - acc: 0.9923 - val_loss: 0.0460 - val_acc: 0.9819\n",
      "Epoch 443/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0201 - acc: 0.9916 - val_loss: 0.0419 - val_acc: 0.9829\n",
      "Epoch 444/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0186 - acc: 0.9922 - val_loss: 0.0435 - val_acc: 0.9831\n",
      "Epoch 445/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0183 - acc: 0.9924 - val_loss: 0.0439 - val_acc: 0.9826\n",
      "Epoch 446/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0203 - acc: 0.9914 - val_loss: 0.0444 - val_acc: 0.9826\n",
      "Epoch 447/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0197 - acc: 0.9918 - val_loss: 0.0471 - val_acc: 0.9816\n",
      "Epoch 448/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0188 - acc: 0.9921 - val_loss: 0.0420 - val_acc: 0.9835\n",
      "Epoch 449/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0185 - acc: 0.9921 - val_loss: 0.0441 - val_acc: 0.9829\n",
      "Epoch 450/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0187 - acc: 0.9924 - val_loss: 0.0463 - val_acc: 0.9827\n",
      "Epoch 451/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0234 - acc: 0.9902 - val_loss: 0.0539 - val_acc: 0.9800\n",
      "Epoch 452/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0213 - acc: 0.9913 - val_loss: 0.0469 - val_acc: 0.9813\n",
      "Epoch 453/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0192 - acc: 0.9921 - val_loss: 0.0439 - val_acc: 0.9830\n",
      "Epoch 454/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0194 - acc: 0.9919 - val_loss: 0.0456 - val_acc: 0.9811\n",
      "Epoch 455/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0197 - acc: 0.9918 - val_loss: 0.0453 - val_acc: 0.9820\n",
      "Epoch 456/500\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 0.0197 - acc: 0.9917 - val_loss: 0.0460 - val_acc: 0.9820\n",
      "Epoch 457/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0197 - acc: 0.9920 - val_loss: 0.0436 - val_acc: 0.9834\n",
      "Epoch 458/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0192 - acc: 0.9921 - val_loss: 0.0476 - val_acc: 0.9814\n",
      "Epoch 459/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0193 - acc: 0.9920 - val_loss: 0.0476 - val_acc: 0.9823\n",
      "Epoch 460/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0187 - acc: 0.9926 - val_loss: 0.0441 - val_acc: 0.9821\n",
      "Epoch 461/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0187 - acc: 0.9926 - val_loss: 0.0457 - val_acc: 0.9830\n",
      "Epoch 462/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0199 - acc: 0.9915 - val_loss: 0.0453 - val_acc: 0.9827\n",
      "Epoch 463/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0189 - acc: 0.9924 - val_loss: 0.0455 - val_acc: 0.9824\n",
      "Epoch 464/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0201 - acc: 0.9917 - val_loss: 0.0442 - val_acc: 0.9830\n",
      "Epoch 465/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0219 - acc: 0.9909 - val_loss: 0.0495 - val_acc: 0.9809\n",
      "Epoch 466/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0199 - acc: 0.9917 - val_loss: 0.0454 - val_acc: 0.9836\n",
      "Epoch 467/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0187 - acc: 0.9923 - val_loss: 0.0425 - val_acc: 0.9838\n",
      "Epoch 468/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0188 - acc: 0.9924 - val_loss: 0.0529 - val_acc: 0.9817\n",
      "Epoch 469/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0190 - acc: 0.9922 - val_loss: 0.0418 - val_acc: 0.9838\n",
      "Epoch 470/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0190 - acc: 0.9922 - val_loss: 0.0438 - val_acc: 0.9835\n",
      "Epoch 471/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0188 - acc: 0.9922 - val_loss: 0.0492 - val_acc: 0.9811\n",
      "Epoch 472/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0186 - acc: 0.9924 - val_loss: 0.0434 - val_acc: 0.9827\n",
      "Epoch 473/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0198 - acc: 0.9919 - val_loss: 0.0432 - val_acc: 0.9832\n",
      "Epoch 474/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0184 - acc: 0.9926 - val_loss: 0.0510 - val_acc: 0.9812\n",
      "Epoch 475/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0199 - acc: 0.9916 - val_loss: 0.0420 - val_acc: 0.9831\n",
      "Epoch 476/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0189 - acc: 0.9920 - val_loss: 0.0441 - val_acc: 0.9835\n",
      "Epoch 477/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0188 - acc: 0.9922 - val_loss: 0.0496 - val_acc: 0.9823\n",
      "Epoch 478/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0211 - acc: 0.9914 - val_loss: 0.0564 - val_acc: 0.9802\n",
      "Epoch 479/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0193 - acc: 0.9919 - val_loss: 0.0420 - val_acc: 0.9834\n",
      "Epoch 480/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0197 - acc: 0.9920 - val_loss: 0.0456 - val_acc: 0.9830\n",
      "Epoch 481/500\n",
      "100000/100000 [==============================] - 1s 7us/step - loss: 0.0196 - acc: 0.9920 - val_loss: 0.0462 - val_acc: 0.9827\n",
      "Epoch 482/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0195 - acc: 0.9919 - val_loss: 0.0462 - val_acc: 0.9810\n",
      "Epoch 483/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0182 - acc: 0.9925 - val_loss: 0.0464 - val_acc: 0.9826\n",
      "Epoch 484/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0184 - acc: 0.9927 - val_loss: 0.0423 - val_acc: 0.9836\n",
      "Epoch 485/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0190 - acc: 0.9919 - val_loss: 0.0464 - val_acc: 0.9816\n",
      "Epoch 486/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0177 - acc: 0.9927 - val_loss: 0.0475 - val_acc: 0.9827\n",
      "Epoch 487/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0187 - acc: 0.9922 - val_loss: 0.0511 - val_acc: 0.9813\n",
      "Epoch 488/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0194 - acc: 0.9919 - val_loss: 0.0427 - val_acc: 0.9834\n",
      "Epoch 489/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0184 - acc: 0.9923 - val_loss: 0.0544 - val_acc: 0.9810\n",
      "Epoch 490/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0197 - acc: 0.9918 - val_loss: 0.0455 - val_acc: 0.9807\n",
      "Epoch 491/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0207 - acc: 0.9914 - val_loss: 0.0493 - val_acc: 0.9803\n",
      "Epoch 492/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0185 - acc: 0.9925 - val_loss: 0.0472 - val_acc: 0.9823\n",
      "Epoch 493/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0189 - acc: 0.9923 - val_loss: 0.0438 - val_acc: 0.9820\n",
      "Epoch 494/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0181 - acc: 0.9926 - val_loss: 0.0464 - val_acc: 0.9819\n",
      "Epoch 495/500\n",
      "100000/100000 [==============================] - 0s 5us/step - loss: 0.0182 - acc: 0.9925 - val_loss: 0.0448 - val_acc: 0.9829\n",
      "Epoch 496/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0186 - acc: 0.9923 - val_loss: 0.0510 - val_acc: 0.9803\n",
      "Epoch 497/500\n",
      "100000/100000 [==============================] - 0s 4us/step - loss: 0.0180 - acc: 0.9925 - val_loss: 0.0494 - val_acc: 0.9813\n",
      "Epoch 498/500\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.0185 - acc: 0.9924 - val_loss: 0.0453 - val_acc: 0.9825\n",
      "Epoch 499/500\n",
      "100000/100000 [==============================] - 1s 7us/step - loss: 0.0197 - acc: 0.9916 - val_loss: 0.0455 - val_acc: 0.9826\n",
      "Epoch 500/500\n",
      "100000/100000 [==============================] - 1s 7us/step - loss: 0.0209 - acc: 0.9912 - val_loss: 0.0451 - val_acc: 0.9819\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs = 500\n",
    "batch_size = 1000\n",
    "\n",
    "ffnn_fitting = ffnn.fit(\n",
    "    X_train, \n",
    "    to_categorical(Y_train),\n",
    "    validation_data=(X_test, to_categorical(Y_test)),\n",
    "    epochs=number_of_epochs,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5cc224cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJCCAYAAAAC4omSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSI6osBIRERHJERVWIiIiIjnyP9wRQyq8WKD9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5c6ef3e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(ffnn_fitting.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
